\newtheorem{thmx}{Theorem}
\renewcommand{\thethmx}{\Alph{thmx}}
\section{Existence of ground state}
The Maxwell equations and ++certain approximations yield the initial value problem ++   

... yields the initial value problem (IVP) ++ ... Question: is this model well-posed? Firstly, does there exist at least one solution? Secondly, does the model have one solution at most? Lastly, does the solution change continuously with the initial conditions? Each of these aspects is formalised in a theorem. Rigorous proofs of these theorems are studied and elaborated upon. In ++, existence (of solutions) is proven under certain conditions. In ++, uniqueness (of solutions) is proven for slighty different conditions. For continuous dependence on the initial conditions, refer to ++.

The existence of a ground state solution to \eqref{ivp} is guaranteed under certain conditions on $g$, which is the nonlinear term in the initial value problem. In this chapter the existence theorem and setting for this problem are stated and a proof will be given based on two lemmas. Note that $\mathbb{R}_+=[0,\infty)$.

\begin{thmx}\label{exithm}
Let $g$ satisfy conditions (A1) to (A7) in section \ref{con}. Then there exists a number $\alpha\in(\alpha_0,\lambda)$ such that the solution $u\in C^2(\mathbb{R}_+)$ of \eqref{ivp} has the properties: \begin{gather*}u(r)>0\text{ for }r\in[0,\infty)\\u'(r)<0\text{ for }r\in(0,\infty)\\ \text{and }\lim_{r\to+\infty}u(r)=0.\end{gather*} If, in addition, we assume $g$ satisfies $$\limsup_{s~\downarrow~0}~\frac{g(s)}{s}<0,$$ then there exist constants $C,\delta>0$ such that $$0<u(r)\leq Ce^{-\delta r} ~~ \textnormal{for} ~ r\in[0,\infty).$$
\end{thmx}

\subsection{Discussion of the theorem}\hfill

\underline{Restricted set of initial conditions} In the initial value problem $\alpha\coloneqq u(0)$ and $u'(0)=0$, and $\alpha\in(0,\infty)$ since the solution depends on $r=|x|$ ($x\in\mathbb{R}^N$). That is, the problem allows any positive initial condition, $\alpha=u(\alpha,0)>0$. However, the properties of the nonlinear term allow for a smaller scope of initial conditions. The theorem restricts the initial conditions to $\alpha\in(\alpha_0,\beta)$. This restriction is a by-product of the proof... {\color{red} ELABORATE}

The dimensions $N\geq2$ are considered. For the case $N=1$, see \cite{}. 

\subsection{Conditions on g}\label{con}\hfill

{\color{red}INTRODUCTION}
\begin{gather}\tag{A1}\label{a1}\text{Let }g\text{ be locally Lipschitz continuous from }\mathbb{R}_+\text{ to }\mathbb{R}\text{ with }g(0)=0.\\
\notag\text{In addition, let }g(u)=0\text{ for }u\leq0.\\
%
\tag{A2}\label{a2}\text{Let }\kappa>0\text{ be finite, where }\kappa\coloneqq\inf(\alpha>0,g(\alpha)\geq0).\\ 
%
\notag\text{Define }G(t)\coloneqq\int_0^t g(s)ds.\\
%
\tag{A3}\label{a3}\text{Let }\alpha_0>\kappa,\text{ where }\alpha_0\coloneqq\inf(\alpha>0,G(\alpha)>0).\\
%
\tag{A4}\label{a4}\text{Let }\underset{s\downarrow\kappa}{\lim}~\frac{g(s)}{s-\kappa}>0.\\
%
\tag{A5}\label{a5}\text{Let }g(s)>0\text{ for }s\in(\kappa,\alpha_0].\\
%
\tag{A6}\label{a6}\text{Let }\lambda\leq\infty,\text{ where }\lambda\coloneqq\inf(\alpha>\alpha_0,g(\alpha)=0).\\
%
\tag{A7}\label{a7}\text{If }\lambda=\infty,\text{ let }\underset{s\to\infty}{\lim}\frac{g(s)}{s^l}=0,\text{ where }\\ \notag l>0\text{ if }N=2,\text{ and }l<\frac{N+2}{N-2}\text{ for }N>2.
\end{gather}
{\color{gray}
Thirdly, note that $g$ is by assumption negative on $(0,\kappa)$ and hence there exists a number $\alpha>0$ such that $G(\alpha)>0$. Here $$G(t)=\int_0^t g(s)ds.$$ Define $\alpha_0\coloneqq\inf(\alpha>0,G(\alpha)>0)$. Then $\alpha_0$ exists by the above and $\alpha_0>\kappa$. 

Fourthly, $g$ satisfies these two conditions regarding $\kappa$ and $g$ on $(\kappa,\alpha_0]$:
\begin{gather}
\label{6}\underset{s\downarrow\kappa}{\lim}~\frac{g(s)}{s-\kappa}>0;\\
g(s)>0~\text{for}~s\in(\kappa,\alpha_0].
\end{gather}

Fifthly, regarding the behaviour of $g$ after $\alpha_0$, the function may remain positive indefinitely or become negative again. In the former case, let $\lambda=+\infty$ and in the latter case, $\lambda\coloneqq\inf(\alpha>\alpha_0,g(\alpha)=0)$. Then by these assumptions, in any case, $\alpha_0<\lambda\leq\infty$. 

Lastly, if $\lambda=\infty$, then $\underset{s\to\infty}{\lim}\frac{g(s)}{s^l}=0$, with $l<\frac{N+2}{N-2}$. Note that this is not defined for $N=2$, in that case, let $l\in\mathbb{R}$.}

{\color{red}REMARKS} Note that the infimum in \eqref{a2} may be infinite. Then $g(u)<0$ for all $u>0$. {\color{red}WHY NOT?} Hence the explicit requirement.

\newtheorem{example}{Example}
\begin{example} The conditions on $g$ are satisfied for $g(u)=-u+u^3.$ {\color{red}COUPLING TO PHYSICS}
% f(x) = -x + x^3, g(x) = (-1/2) x^2 + 1/4 x^4
\end{example}

\subsection{The solutions are defined on the semi-definite interval}\hfill\label{semidef}

Let $\alpha\in(\kappa,\lambda)$ and let $u(\alpha,r)$ be the corresponding solution of \eqref{ivp}. That $g$ is locally Lipschitz continuous implies that the solution $u(\alpha,r)$ is defined on some interval $[0,r_\alpha)$. Remember, the solution may have asymptotes. Boundedness of the solution is a sufficient and necessary condition for $r_\alpha=\infty$. Note that the initial condition is positive, $\alpha>0$. Claim: the solution $u(\alpha,r)$ is bounded above by the initial condition, $u(\alpha,r)\leq u(\alpha,0)=\alpha$ for $r\geq0$. To see this, multiply the \eqref{ivp} by $u'$ and integrate between 0 and $r$ to obtain:

\begin{align}\label{ivpint}
-u''-\frac{N-1}{r}u'&=g(u)\nonumber\\
-\int_0^r\left[u'(s)u''(s)\right]ds-\int_0^r\left[\frac{N-1}{s}[u'(s)]^2\right]ds&=\int_0^r\left[u'(s)g(u(s))\right]ds\nonumber\\
\notag\text{Use }\frac{d}{dr}\left[(u'(r))^2\right]=2u'(r)u''(r)&:\\
-\frac{1}{2}[u'(r)]^2-(N-1)\int_0^r[u'(s)]^2\frac{ds}{s}&=\int_0^r g(u(s))\frac{du}{ds}ds=\int_0^r g(u)du\nonumber\\
-\frac{1}{2}[u'(r)]^2-(N-1)\int_0^r[u'(s)]^2\frac{ds}{s}&=G(u(\alpha,r))-G(\alpha)
\end{align}

Note that $u'(0)=0$ in evaluating the integrand from the first term of the integral. Suppose that $u'>0$ for $r$ small. Then $u(\alpha,r)>u(\alpha,0)$ and since $G$ is nondecreasing on $(\kappa,\lambda)$ the right hand side is positive $G(u(\alpha,r))-G(\alpha)>0$. Then
\begin{align*}
-\frac{1}{2}[u'(r)]^2-(N-1)\int_0^r[u'(s)]^2\frac{ds}{s}&>0\\
\frac{1}{2}[u'(r)]^2+(N-1)\int_0^r[u'(s)]^2\frac{ds}{s}&<0\quad\text{\Lightning},
\end{align*}
which is clearly impossible, both terms are positive. Conclusion: the solution is decreasing at first and bounded above by the initial condition. In fact, suppose $u(\alpha,r)\geq\alpha$ for some $r_0>0$, then again $G(u(\alpha,r_0))-G(\alpha)>0$ and the same contradiction is found. 
%Define $r_1\coloneqq\inf(r>r_0,u(\alpha,r_1)>0)$. By condition (A1), $g(u(r_0))=0$.   {\color{red} How will the derivative evolve now? The derivative will vanish hyperbolically from there. In other words, let $r_0>0$ such that $u(\alpha,r_0)=0$ and $u'(\alpha,r_0)\leq0$, then for $r\geq r_0$:

It remains to show $u(\alpha,r)$ has a lower bound. Let $r_0\coloneqq\inf(r>0,u(\alpha,r_0)=0).$ Suppose $r_0<\infty$. (Note that $r_0=\infty\implies u(\alpha,r)>0$ for all $r>0$, hence $u(\alpha,r)$ is bounded.) If $u'(\alpha,r_0)=0$, then $u(\alpha,r)\equiv0$. Thus $u'(\alpha,r_0)<0$. Claim: the derivative will decay hyperbolically for $r\geq r_0$ as,  $$u'(\alpha,r)=\big(\frac{r_0}{r}\big)^{N-1}u'(\alpha,r_0)\geq u'(\alpha,r_0)$$.

To see this, use condition (A1) in \eqref{ivp},
%(When $u(\alpha,r)\leq0$, $g(u(r))=0$.) To be safe, let $r_1=\inf(r>r_0,u(\alpha,r_1)\geq0)$. Then $u(\alpha,r)\leq0$ on $[r_0,r_1]$ and 
$$-u''-\frac{N-1}{r}u'=0,$$%,\text{ for }r\in[r_0,r_1].$$ 
which is valid for $u(\alpha,r)\leq0.$ To be safe, let $r_1=\inf(r>r_0,u(\alpha,r_1)=0)$ and suppose $r_1<\infty$. Then $u(\alpha,r)\leq0$ on $[r_0,r_1]$. Now solve for $u'=u'(\alpha,r)$ on $[r_0,r_1]$:

\begin{align*}
-\frac{d}{dr}u'-\frac{N-1}{r}u'&=0\\
\frac{du'}{dr}&=-\frac{N-1}{r}u'\\
\frac{du'}{u'}&=-\frac{N-1}{r}dr\\
\left.\ln{u'}\right\rvert_{r_0}^r&=\left[(N-1)\ln{r}\right]_r^{r_0}\\
\ln{u'(r)}-\ln{u'(r_0)}&=(N-1)\left[\ln{r_0}-\ln{r}\right]\\
\frac{u'(r)}{u'(r_0)}&=\left(\frac{r_0}{r}\right)^{N-1}\\
u'(\alpha,r)=\big(\frac{r_0}{r}\big)^{N-1}u'(\alpha,r_0)&\geq u'(\alpha,r_0).%\text{ on }[r_0,r_1].
\end{align*}

%This expression is valid for $u(\alpha,r)\leq0$. Let $r_1=\inf(r>r_0,u(\alpha,r_1)=0)$. Suppose $r_1<\infty$. Then $u'(\alpha,r)\leq0$ on $[r_0,r_1]$. But $u(\alpha,r_1)>u(\alpha,r)$ for all $r\in(r_0,r_1)$. A contradiction, hence $u(\alpha,r)<0$ on $[r_0,\infty)$ and the hyperbolic decay holds on $[r_0,\infty)$. 
It follows that $u'(\alpha,r)\leq0$ on $[r_0,r_1]$. Hence $u(\alpha,r)<0$ on $(r_0,r_1]$, which contradicts the assumption on $r_1$. Thus $r_1=\infty$ and $u(\alpha,r)<0$ for $r>r_0$. Note how $u'(\alpha,r)\uparrow0$ for $r\to\infty$. Then $u(\alpha,r)$ has some lower bound. Since the solution is bounded, it is defined on $(0,\infty)$.

\subsection{The shooting method}\hfill

Now any $\alpha\in I$ is defined on $(0,\infty)$. Also, $g(\alpha)>0$ and therefore $u''(\alpha,0)<0$ by the \eqref{ivp}: $u'(0)=0$ and $-u''(\alpha,0)=g(u(\alpha,0))=g(\alpha)>0$. Then for $r>0$ and small: $u'(\alpha,r)<0$ and $u(\alpha,r)>0$. To analyse the behaviour of the solutions for larger $r$, distinguish two sets of initial conditions: solutions that have a vanishing derivative in some point and are positive up to and including that point, and solutions and vanish in some point, but have negative derivative up to and including that point. {\color{red}These sets are defined below.} If these sets are open, nonempty and disjoint, then there exist elements $\alpha^*\in I$ such that $u(\alpha^*,r)>0$ for all $r\geq0$ and $u'(\alpha^*,r)<0$ for all $r>0$. By \cref{lem} and its proof, the sets have these properties and hence such elements exist. Intuitively, a solution that is positive everywhere and has negative derivative everywhere has a limit for $r$ tending to infinity, and is possibly ground state. However, that also requires that this limit is zero.

\begin{lemma}\label{llemma} 
Let $g$ be locally Lipschitz continuous on $\mathbb{R_+}$ such that $g(0)=0$. Let $\alpha_1\in(0,\infty)$ be such that $u(\alpha_1,r)>0$ for all $r\geq0$ and $u'(\alpha_1,r)<0$ for all $r>0$. Then the number $l=\underset{r\to\infty}{\lim}u(\alpha_1,r)$ satisfies $g(l)=0$. Furthermore, if $g$ satisfies \eqref{6} and $g(\kappa)=0$, then $l\neq\kappa$.
\end{lemma}
\begin{proof}
Let $\alpha_1$ be as assumed in the lemma and let $r$ tend to infinity in the \eqref{ivp}:
\begin{equation}\label{ivplim}\limrtoinf\Big[u''(\alpha_1,r)+\frac{N-1}{r}u'(\alpha_1,r)+g(u(\alpha_1,r))\Big]=0,\end{equation} and note that $l=\limrtoinf u(r)$. To prove the first statement of the lemma: the number $l=\limrtoinf u(r)$ satisfies $g(l)=0$, information about the limits of $u'$ and $u''$ is required. In fact, they both need to converge to zero. Then $g(l)=0$ and it remains to show that $g\neq\kappa$. \underline{Claim:} both $u''\to0$ and $u'\to0$ as $r\to\infty.$
\begin{proof}[Proof of the claim] Remember expression \eqref{ivpint}, where the \eqref{ivp} was multiplied by $u'$ and integrated from 0 to $r$. Now evaluate the limit for $r$ tending to infinity: 
\begin{align*}
	\underset{r\to\infty}{\lim}\left[-\frac{1}{2}[u'(\alpha_1,r)]^2-(N-1)\int_0^r[u'(\alpha_1,s)]^2\frac{ds}{s}\right]
        &=\limrtoinf\left[G(u(\alpha,r))-G(\alpha)\right] \\
    \underset{r\to\infty}{\lim}~\frac{1}{2}[u'(\alpha_1,r)]^2+(N-1)\underset{r\to\infty}{\lim}\int_0^r[u'(\alpha_1,s)]^2\frac{ds}{s}
        &=G(\alpha_1)-\underset{r\to\infty}{\lim}G(u(\alpha,r))\\
    \underset{r\to\infty}{\lim}~\frac{1}{2}[u'(\alpha_1,r)]^2+(N-1)\int_0^\infty[u'(\alpha_1,s)]^2\frac{ds}{s}
        &=G(\alpha_1)-G(l)\\
    \underset{r\to\infty}{\lim}~\frac{1}{2}[u'(\alpha_1,r)]^2+(N-1)\int_0^\infty[u'(\alpha_1,s)]^2\frac{ds}{s}
        &<\infty
%G(\alpha_1)=G(l)+\underset{r\to\infty}{\lim}\frac{1}{2}\big[u'(\alpha_1,r)\big]^2+(N-1)\int_0^{\infty}\big[u'(\alpha_1,s)\big]^2\frac{ds}{s} \\
%      G(\alpha_1)-G(l)=\underset{r\to\infty}{\lim}\frac{1}{2}\big[u'(\alpha_1,r)\big]^2+(N-1)\int_0^{\infty}\big[u'(\alpha_1,s)\big]^2\frac{ds}{s} \\
%     \text{noting that }G(l)<G(\alpha_1)<\infty,\text{ hence }0<G(\alpha_1)-G(l)<\infty \\
%\comm{\implies\int_0^{\infty}\left[u'(\alpha_1,s)\right]^2\frac{ds}{s}<\infty,~&\underset{r\to\infty}{\lim}[u'(\alpha_1,r)]^2<\infty}
\end{align*} 
and thus both terms of the left hand side should be finite, so $u'(\alpha_1,r)$ converges as $r\to\infty.$ Remember now that $u(\alpha_1,r)$ is bounded, so the derivative must converge to 0: $$\underset{r\to\infty}{\lim}u'(\alpha_1,r)=0.$$ Now return to \eqref{ivplim} and use the acquired information: 
\begin{align*}
	\limrtoinf\Big[u''(\alpha_1,r)+\frac{N-1}{r}u'(\alpha_1,r)+g(u(\alpha_1,r))\Big]&=0\\ 
	-\limrtoinf\left[u''(\alpha_1,r)\right]
    -\limrtoinf\left[\frac{N-1}{r}u'(\alpha_1,r)\right]&=\limrtoinf g(u(\alpha_1,r))\\
	-\limrtoinf\left[u''(\alpha_1,r)\right]&=g(l)
\end{align*}

But $g(l)$ is finite since $u$ is bounded and thus $u''$ converges as $r$ tends to infinity. By similar argument the limit is zero. Note that $u'$ is bounded, so $u''$ has to converge to zero. $$\limrtoinf u''(\alpha_1,r)=0.$$ So the claim is valid and $g(l)=0$.\end{proof}  

It remains to be shown that if $g$ satisfies \eqref{6} then $l\neq\kappa.$ Suppose to the contrary $l=\kappa$. Then introduce the following substitution: 
$$v(r)=r^{(1/2)(N-1)}\left[u(r)-\kappa\right],$$ 

where $u(r)=u(\alpha_1,r)$. Combining this function, its derivatives and the \eqref{ivp}, one can obtain a differential equation in $v$. This will then be used to argue that $l=\kappa$ can only lead to contradictions when $g$ satisfies \eqref{6} and $g(\kappa)=0$. 

Calculate the derivatives of $v$:
\begin{align*}v(r)&=r^{(N-1)/2}\left[u(r)-\kappa\right] \\
v'(r)&=\frac{1}{2}(N-1)r^{(N-3)/2}\left[u(r)-\kappa\right]+r^{(N-1)/2}u'(r)\\
\begin{split}v''(r)&=\frac{1}{4}(N-1)(N-3)r^{(N-5)/2}\left[u(r)-\kappa\right]\\&+\frac{1}{2}(N-1)r^{(N-3)/2}u'(r)+\frac{1}{2}(N-1)r^{(N-3)/2}u'(r)\\&+r^{(N-1)/2}u''(r)\end{split}\\
v''(r)&=\frac{1}{4}(N-1)(N-3)r^{(N-5)/2}\left[u(r)-\kappa\right]+(N-1)r^{(N-3)/2}u'(r)+r^{(N-1)/2}u''(r)
\end{align*} and take out any integer powers of $r$: (then all terms carry $r^{(N-1)/2}$)
\begin{align*}
v(r)&=r^{(N-1)/2}\left[u(r)-\kappa\right] \\
v'(r)&=\frac{1}{2}(N-1)r^{(N-1)/2}r^{-1}\left[u(r)-\kappa\right]+r^{(N-1)/2}u'(r)\\
v''(r)=&\frac{1}{4}(N-1)(N-3)r^{(N-1)/2}r^{-2}\left[u(r)-\kappa\right]+\underline{(N-1)r^{(N-1)/2}r^{-1}u'(r)+r^{(N-1)/2}u''(r)}
\end{align*}
and multiply the \eqref{ivp} by $r^{(N-1)/2}$:
\begin{align*} -u''(r)-(N-1)r^{-1}u'(r)&=g(u(r))\\
-r^{(N-1)/2}u''(r)-(N-1)r^{(N-1)/2}r^{-1}u'(r)&=g(u(r))r^{(N-1)/2}\tag{*}
\end{align*}
to see that the last two (underlined) terms of $v''(r)$ are equal (up to a minus sign) to the left hand side of (*). That means we can write $-g(u(r))r^{(N-1)/2}$ in the expression for $v''(r)$: $$v''(r)=\frac{1}{4}(N-1)(N-3)r^{(N-1)/2}r^{-2}\left[u(r)-\kappa\right]-g(u(r))r^{(N-1)/2}.$$ Now take out a factor $v(r)=r^{(N-1)/2}\left[u(r)-\kappa\right]$ and multiply by $-1$ to obtain: \begin{align*}
v''(r)&=r^{(N-1)/2}\left[u(r)-\kappa\right]\left\{
		\frac{1}{4}(N-1)(N-3)r^{-2}-\frac{g(u)}{u(r)-\kappa}\right\}\\
v''(r)&=v\left\{\frac{(N-1)(N-3)}{4r^2}-\frac{g(u)}{u(r)-\kappa}\right\}\\
-v''(r)&=\left\{\frac{g(u)}{u(r)-\kappa}-\frac{(N-1)(N-3)}{4r^2}\right\}v
\end{align*}
Also $v(r)>0$ for $r\geq0$ by definition of $v(r)$. The $r$-term is positive and increasing and the term in brackets is positive and decreasing. Thus $v(r)$ is positive. As mentioned, this differential equation in $v$ is what will be used to show that $l=\kappa$ is impossible under the assumptions on $g$. Before diving into the cases, a lower bound for the term in brackets will be calculated. Remember that by assumption $u(r)\downarrow\kappa$ as $r\uparrow\infty$ and $g$ satisfies \eqref{6}. Claim: there exist positive numbers $\omega$ and $R_1$ such that: $$\frac{g(u)}{u(r)-\kappa}-\frac{(N-1)(N-3)}{4r^2}\geq\omega\quad\text{for all}~r\geq R_1$$
\begin{proof}[Proof of the claim] By assumption, $g(\kappa)=0$ and using the definition of the derivative: $$\underset{u(r)\downarrow\kappa}{\lim}~\frac{g(u(r))}{u(r)-\kappa}=\underset{u(r)\downarrow\kappa}{\lim}~\frac{g(u(r))-g(\kappa)}{u(r)-\kappa}~\overset{(u(r)-\kappa=h)}{=}~\underset{h\downarrow0}{\lim}~\frac{g(\kappa+h)-g(\kappa)}{h}=g'(\kappa^+)$$ and $g'(\kappa^+)>0$ by conditions on $g$. Let $\epsilon>0$. Then there exists $R_\epsilon>0$ such that \begin{gather*}r\geq R_\epsilon\implies\left|\frac{g(u(r))}{u(r)-\kappa}-g'(\kappa)\right|\leq\frac{\epsilon}{2}\\ %and by definition of the absolute value $$-\frac{\epsilon}{2}\leq\frac{g(u(r)}{u(r)-\kappa}-g'(\kappa)\leq\frac{\epsilon}{2}$$ of which the first inequality will be used: \begin{gather*}-\frac{\epsilon}{2}\leq\frac{g(u(r)}{u(r)-\kappa}-g'(\kappa)\\ \frac{g(u(r)}{u(r)-\kappa}-g'(\kappa)\geq-\frac{\epsilon}{2}\\ 
\implies\frac{g(u(r))}{u(r)-\kappa}\geq g'(\kappa)-\frac{\epsilon}{2}\tag{A} \end{gather*}Note also that there exists $R_\theta>0$ such that \begin{gather*}r\geq R_\theta\implies\left|\frac{(N-1)(N-3)}{4r^2}\right|\leq\frac{\epsilon}{2}\\% and again using the definition of the absolute value: \begin{gather*}-\frac{\epsilon}{2}\leq\frac{(N-1)(N-3)}{4r^2}\leq\frac{\epsilon}{2}\\ 
\implies\frac{(N-1)(N-3)}{4r^2}\geq-\frac{\epsilon}{2}.\tag{B}\\ \text{Addition yields: }\frac{g(u(r))}{u(r)-\kappa}-\frac{(N-1)(N-3)}{4r^2}\geq g'(\kappa)-\epsilon\tag{A+B}\end{gather*} And the claim is valid, let $\omega=g'(\kappa)-\epsilon$ with $\epsilon>0$ small enough and $R_1=\max(R_\epsilon,R_\theta)$. \end{proof}

From this, $-v''(r)>0$ for $r\geq R_1$ and thus $v''(r)<0$ for $r\geq R_1$, which implies $v'(r)\downarrow L\geq-\infty$ as $r\uparrow\infty$. To see this, remember that $v''(r)<0$ implies $v(r)$ will be concave down, that is, the tangent line will lie above the function. Even if the derivative $v'(r)$ would be positive for $r$ slightly larger than $R_1$, since $v''(r)<0$ indefinitely, the function will remain concave down and the derivative will become negative and stay negative. Consider the following possible limits $L$: $L<0$ and $L\geq0$. In the first case, $L<0$, then $v(r)\to-\infty$ as $r\to\infty$ which is impossible, since $v(r)>0$ for $r\geq0$ \Lightning. Then consider $L\geq0$. Note that $v'(R_1)\geq0$. Indeed, suppose $v'(R_1)<0$. Then since $v''(r)<0$, the function is concave down and the derivative will only decrease. Then the limit of the derivative can not be $L\geq0$. Thus $v'(R_1)\geq0$. This, by the same argument, implies the derivative will be positive for $r\geq R_1$. Suppose the derivative is negative for some $R_2>R_1$ then the derivative will remain negative for $r\geq R_2$ as $v''(r)<0$. Clearly, $v(r)\geq v(R_1)>0$. This implies that $-v''(r)\geq\omega v(R_1)>0$ and therefore $v'(r)\downarrow-\infty$ as $r\to\infty$. Why? Because if $v''(r)<0$ indefinitely, the limit of $v'(r)$ can not be $L\geq0$, as the derivative will decrease while $v''(r)<0$. Since $v''(r)<0$ indefinitely, the limit of $v'(r)$ will be minus infinity. Again, this contradicts $v(r)>0$ for $r\geq0$. \Lightning Conclusion: in any case $v''(r)<0$ for $r\geq R_1$ which implies $v'(r)\downarrow-\infty$, which contradicts $v(r)>0$ for $r\geq0$ and hence $l=\kappa$ is an impossible assumption under the assumptions on $g$ and hence $l\neq\kappa$. This concludes the proof of the lemma.
\end{proof}

\subsection{P and N are nonempty and open}

\begin{lemma}\label{lem} Under the assumptions of \cref{exithm}, the sets $P$ and $N$ are nonempty, disjoint and open.
\end{lemma}
\begin{proof}
The sets $P$ and $N$ are disjoint by definition. The order in which the statements of the lemma will be proven is as follows: $P$ is nonempty, $P$ is open, $N$ is open. That $N$ is nonempty is outside the scope of this report. See \cite{ber} for the proof.

\subsection*{P is non-empty} 
To prove that $P$ is non-empty, let $\alpha_p\in(\kappa,\alpha_0]$. 
Consider the following cases: (i) $\alpha_p\in N$, (ii) $\alpha_p\notin P$, (iii) $\alpha_p\in P$ and note they are mutually exclusive. If the initial condition is in $N$, then the solution vanishes in some point $r_0$. Then, if the initial condition is not in $N$, the solution does not vanish anywhere: $u(\alpha_p,r)>0$ for $r\geq0$. If the initial condition is \underline{not} in $P$, then the derivative is negative everywhere. Disproving these two cases yields the properties: the solution is positive everywhere, but the derivative vanishes in some point $r_0$, which is exactly the definition of $P$. %The sets $P$ and $N$ are disjoint and the initial condition cannot be in $P$ and not in $P$ and $P$.
Hence disproving case (i) and (ii) implies case (iii) applies.

First, suppose by contradiction that $\alpha_p\in N$. Then by definition, there exists a $r_0$ such that $u(\alpha_p,r_0)=0$ and $u'(\alpha_p,r_0)<0$. Now evaluate \eqref{ivpint} in $r_0$, using $u(\alpha_p,r_0)=0$, $G(0)=0$ and that on $(0,r_0]$ the derivative is strictly negative:
\begin{align*}-\frac{1}{2}[u'(r_0)]^2-(N-1)&\int_0^{r_0}[u'(s)]^2\frac{ds}{s}=G(u(\alpha_p,r_0))-G(\alpha_p)\\
G(\alpha_p)-G(u(\alpha_p,r_0))&=\frac{1}{2}[u'(r_0)]^2+(N-1)\int_0^{r_0}[u'(s)]^2\frac{ds}{s}\\
G(\alpha_p)-G(0)&=\frac{1}{2}[u'(r_0)]^2+(N-1)\int_0^{r_0}[u'(s)]^2\frac{ds}{s}\\
G(\alpha_p)&=\frac{1}{2}[u'(r_0)]^2+(N-1)\int_0^{r_0}[u'(s)]^2\frac{ds}{s}\\
    \implies &G(\alpha_p)>0,
\end{align*}
but the assumption $\alpha_p\in(\kappa,\alpha_0]$ implies $G(\alpha_p)<0$, a contradiction, hence $\alpha_p\notin N$.

Next, suppose $\alpha_p\notin P$, then $u(\alpha_p,r)>0$ for $r\geq0$ and $u'(\alpha_p,r)<0$ for $r>0$. That implies $u(\alpha_p,r)\downarrow l\geq0$ as $r\uparrow\infty$ and by \cref{llemma} the limit is zero, $l=0$. Similar to the previous argument and the proof of \cref{llemma}, observe \eqref{ivpint} for $r$ tending to infinity, and note the following: $l=\limrtoinf u(\alpha_p,r)$, $G(l)=G(0)=0$, $\limrtoinf\left[u'(\alpha_p,r)\right]^2=0$ as well as the lower bound on the integral term $\int_0^\infty\left[u'(\alpha_p,s)\right]^2\frac{ds}{s}\geq0$, to conclude that:
\begin{align*}
\limrtoinf\left[G(\alpha_p)-G(u(\alpha_p,r))\right]&=\limrtoinf\left[\frac{1}{2}[u'(r)]^2+(N-1)\int_0^{r}[u'(s)]^2\frac{ds}{s}\right]\\
G(\alpha_p)-G(l)&=0+(N-1)\int_0^{\infty}[u'(s)]^2\frac{ds}{s}\\
G(\alpha_p)-G(0)&\geq0\\
&\implies G(\alpha_p)\geq0,
\end{align*}
to reach the same contradiction, $\alpha_p\in(\kappa,\alpha_0]\implies G(\alpha_p)<0$. Hence $\alpha_p\in P$, and any $\alpha\in(\kappa,\alpha_0]$ is in $P$, that is, $(\kappa,\alpha_0]\subset P$ and $P$ is nonempty.\hfill\ensuremath{\square}\vspace{1em}

The proofs for openness of both $P$ and $N$ invoke continuous dependence on the initial data as explained in detail in for example \cite{codlev}.

\subsection*{P is open} To prove that $P$ is open, note that for $\alpha\in P$, $$r_0=\inf\{r>0,~u'(\alpha,r)=0,~u(\alpha,r)>0\}>0$$ and\begin{empheq}[left = \empheqlbrace]{align*}
	&u(\alpha,r)>0\quad\text{for all }r\in[0,r_0] \\
    &u'(\alpha,r)<0\quad\text{for all }r\in(0,r_0).
\end{empheq}
From \eqref{ivp} follows $u''(\alpha,r_0)=-g(u(\alpha,r_0))$. Consider $u''(\alpha,r_0)=0$. Then $g(u(\alpha,r_0))=0$. The only zero of $g$ where $0<u(\alpha,r_0)<\alpha$ is $\kappa$, i.e. $u(\alpha,r_0)=\kappa$. But since $u'(\alpha,r_0)=0$ and $u''(\alpha,r_0)=0$, $u(\alpha,r)\equiv\kappa$, which is impossible. 

Consider $u''(\alpha,r_0)\neq0$. Then because the derivative was negative up to $r_0$ and has now vanished, $u''(\alpha,r_0)>0$. This implies the derivative is positive to the right of $r_0$ and there exists a $r_1>r_0$ such that $u(\alpha,r)>u(\alpha,r_0)$ for all $r\in(r_0,r_1]$. {\color{red} FIGURE}. By continuous dependence on the initial condition, let $\alpha^*$ be sufficiently close to $\alpha$ then for all $r\in(0,r_1]$ the following hold:\begin{empheq}[left=\empheqlbrace]{align*}
	&u(\alpha^*,r_1)>u(\alpha^*,r_0) \\
    &\alpha^*>u(\alpha^*,r)>0
\end{empheq} which can be interpreted as: for $\alpha^*$ sufficiently small, $u(\alpha^*,r_1)$ is still above $u(\alpha^*,r_0)$, the derivative vanishes in some point $r_0^*\in(0,r_1]$ and the solution does not vanish on $(0,r_1]$. Then these properties together imply $\alpha^*\in P$ and hence $P$ is open. ($P$ is open if for any initial condition $\alpha$ in $P$, there exists a real number $\epsilon_\alpha>0$ such that points whose distance from $\alpha$ is less than $\epsilon_\alpha$ are also in $P$.)\hfill\ensuremath{\square}

\subsection*{N is open} To prove that $N$ is open, note that for $\alpha\in N$, $$r_0=\inf\{r>0,~u(\alpha,r)=0,~u'(\alpha,r)<0\}>0$$ and\begin{empheq}[left = \empheqlbrace]{align*}
	&u(\alpha,r)>0\quad\text{for all }r\in[0,r_0) \\
    &u'(\alpha,r)<0\quad\text{for all }r\in(0,r_0].
\end{empheq}
In any case, since $u(\alpha,r_0)=0$, $g(u(\alpha,r_0))=g(0)=0$. In fact, remember $g(u)=0$ for $u\leq0$. Note that $u'(\alpha,r_0)<0$. Then there exists $r_1>r_0$ such that $u(\alpha,r)<u(\alpha,r_0)=0$ for $r\in(r_0,r_1]$. The \eqref{ivp} yields for $r\in(r_0,r_1]$:\begin{gather*}u''(\alpha,r)=-\frac{N-1}{r}u'(\alpha,r)\\ u'(\alpha,r)=\left(\frac{r_0}{r}\right)^{N-1}u'(\alpha,r_0)\geq u'(\alpha,r_0)\end{gather*} Thus $u'(\alpha,r)\uparrow0$ for $r\to\infty$. Note that the function does not become positive, $r_1$ could be extended to infinity. By continuous dependence on the initial condition, let $\alpha^*$ be sufficiently close to $\alpha$ that for all $r\in(0,r_1]$ the following hold:\begin{empheq}[left=\empheqlbrace]{align*}
	&u(\alpha^*,r_1)<u(\alpha^*,r_0) \\
    &u'(\alpha^*,r)=\left(\frac{r_0^*}{r}\right)^{N-1}u'(\alpha,r_0^*)
\end{empheq} where $r_0^*$ uniquely satisfies $u(\alpha^*,r_0^*)=0$ on $(0,r_1]$. This can be interpreted as: for $\alpha^*$ sufficiently small, $u(\alpha^*,r_1)$ is still below $u(\alpha^*,r_0)$ (now not necessarily zero) and the derivative decays hyperbolically after the solution vanishes in some point $r_0^*\in(0,r_1]$. Then these properties together imply $\alpha^*\in N$ and hence $N$ is open. ($N$ is open if for any initial condition $\alpha$ in $N$, there exists a real number $\epsilon_\alpha>0$ such that points whose distance from $\alpha$ is less than $\epsilon_\alpha$ are also in $N$.)
\end{proof}

\subsection{Conclusions on existence}\hfill

Under the conditions on $g$ as specified after the theorem, there exists a ground state solution to \eqref{ivp} as proven by ODE methods. Remember that the interval of definition of solutions with initial condition $\alpha\in(\kappa,\lambda)$ is $(0,\infty)$ and that any solution that is positive everywhere and has negative derivative everywhere is convergent. By the properties of $g$ and the \eqref{ivp}, this limit is a zero of $g$ and if $\kappa$ is a zero of $g$, then $l\neq\kappa$ by \cref{llemma}. Lastly, the shooting method requires that the sets of initial conditions $P$ and $N$ are disjoint, nonempty and open, as proven by \cref{lem}. Then there exist elements with intial condition $\alpha$ not in $P$ or $N$ that have $u(\alpha,r)>0$ for $r\geq0$ and $u'(\alpha,r)<0$ for $r>0$. Such a solution by \cref{llemma} tends to zero for $r$ to infinity and hence is a ground state solution.









\comm{
\subsection{Previously}
\vspace{3cm}
In \cite{ber}, the existence of a ground state solution to \eqref{ivp} is formalised in a theorem of which a proof is given. This chapter studies that paper.

The existence of a ground state solution to \eqref{ivp} corresponds to the existence of an initial condition $\alpha_0$ belonging to solution set $G$. This is not guaranteed, the set G could be empty. This is the case if none of the solutions exhibit ground state behaviour. 

As illustrated in chapter \ref{not}, the solution sets are disjoint. Hence, the set $G$ is non-empty if both $P$ and $N$ are non-empty and open, and additionally, a solution not belonging to $P$ or $N$ satisfies the ground state conditions. Summarising, by proving the following statements, there exist solutions that do not belong to either $P$ or $N$. Then it remains to show such a solution belongs to $G$.

[[A ground state solution will be found in $(\zeta_0,\beta)$, because...]]

A proof of the existence theorem thus requires the following statements to be true:
\begin{enumerate}
\item The set $P$ is non-empty,
\item The set $P$ is open,
\item The set $N$ is non-empty,
\item The set $N$ is open,
\item For $\alpha_1 \not\in (P\cup N)$, $\underset{r\to\infty}{\lim}u(\alpha_1,r)\neq\kappa$.
\end{enumerate}
\comm{
The third statement is hard to prove, that is, it requires knowledge outside the scope of a bachelor's thesis. For last statement, admit the following lemma.

\begin{lemma}\label{llemma} 
Let $g$ be locally Lipschitz continuous on $\mathbb{R_+}$ such that $g(0)=0$. Let $\alpha_1\in(0,\infty)$ be such that $u(\alpha_1,r)>0$ for all $r\geq0$ and $u'(\alpha_1,r)<0$ for all $r>0$. Then the number $l=\underset{r\to\infty}{\lim}u(\alpha_1,r)$ satisfies $g(l)=0$. Furthermore, if $g$ satisfies \eqref{6} and $g(\kappa)=0$, then $l\neq\kappa$.
\end{lemma}

What does this lemma yield? [Given the \eqref{ivp} with nonlinear function $g$ and certain conditions on $g$, for \emph{any initial condition} $\alpha_1\in(0,\infty)$ not belonging to $P$ or $N$, the solution $u$ has a limit $l$ for $r$ tending to infinity and the function $g$ vanishes for this limit value.] Also, if $g$ vanishes in $\kappa$, then the limit value $l$ is different from $\kappa$. In fact, it will turn out $l=0$, if $\alpha_1\in(0,\lambda)$, since a solution is decreasing and $\lambda$ is the next zero of $g$ upwards of $\kappa$. Conclusion: such a solution is a ground state solution.

%\text{ and both terms of right hand side are finite:}
\begin{proof} To prove $g(l)=0$, let $r$ tend to infinity in \eqref{ivp}: \begin{equation}\limrtoinf\Big[u''(r)+\frac{N-1}{r}u'(r)+g(u(r))=0\Big],\end{equation} and note that $l=\limrtoinf u(r)$. \underline{Claim:} both $u''$ and $u'$ converge to zero for $r$ tending to infinity. Then $g(l)=0$ and it remains to show that $g\neq\kappa$.
\begin{proof}[Proof of the claim] Observe identity \eqref{ivpint} for $r$ tending to infinity,
\begin{empheq}{align*}
	\underset{r\to\infty}{\lim}\Big[&G(\alpha_p)=G(u(\alpha_1,r))+\frac{1}{2}\big[u'(\alpha_1,r)\big]^2+(N-1)\int_0^{r}\big[u'(\alpha_1,s)\big]^2\frac{ds}{s}\Big] \\
    &G(\alpha_1)=G(l)+\underset{r\to\infty}{\lim}\frac{1}{2}\big[u'(\alpha_1,r)\big]^2+(N-1)\int_0^{\infty}\big[u'(\alpha_1,s)\big]^2\frac{ds}{s} \\
     &G(\alpha_1)-G(l)=\underset{r\to\infty}{\lim}\frac{1}{2}\big[u'(\alpha_1,r)\big]^2+(N-1)\int_0^{\infty}\big[u'(\alpha_1,s)\big]^2\frac{ds}{s} \\
    &\text{noting that }G(l)<G(\alpha_1)<\infty,\text{ hence }0<G(\alpha_1)-G(l)<\infty \\
    \implies &\int_0^{\infty}u'(\alpha_1,s)\big]^2\frac{ds}{s}<\infty,~\underset{r\to\infty}{\lim}[u'(\alpha_1,r)]^2<\infty
\end{empheq}
But this integral can only be finite if $u'(\alpha_1,r)$ converges. [[the limit is 0]] 

Observe \eqref{ivp} for $r\to\infty$, $$\limrtoinf\Big[u''(r)+\frac{N-1}{r}u'(r)+g(u(r))=0\Big],$$ then since $u'$ and $g$ are bounded, $u''$ must converge. Since $u'$ is bounded, $u''\to0$ as $r\to\infty$. 
\end{proof}

Now to show $g\neq\kappa$...
\end{proof}

Returning to the other statements,...}
}\comm{
\subsection*{$P$ is non-empty} 
To prove that P is non-empty, let $\alpha_p\in(\gamma,\kappa]$. 
Consider the following cases: (i) $\alpha_p\in N$, (ii) $\alpha_p\notin P$, (iii) $\alpha_p\in P$ and note they are mutually exclusive [[figure]]. %The sets $P$ and $N$ are disjoint and the initial condition cannot be in $P$ and not in $P$ and $P$. 
Hence disproving case (i) and (ii) implies case (iii) applies.

First, suppose by contradiction that $\alpha_p\in N$. Then by definition, there exists a $r_0$ such that $u(\alpha_p,r_0)=0$ and $u'(\alpha_p,r_0)<0$. Now evaluate \eqref{ivpint} in $r_0$,
\begin{empheq}{align*}
	&G(\alpha_p)=G(u(\alpha_p,r_0))+\frac{1}{2}\big[u'(\alpha_p,r_0)\big]^2+(N-1)\int_0^{r_0}\big[u'(\alpha_p,s)\big]^2\frac{ds}{s} \\
    &\text{noting that }G(u(\alpha_p,r_0)=G(0)=0,~[u'(\alpha_p,r_0)]^2>0\text{ and } \int_0^{r_0}\big[u'(\alpha_p,s)\big]^2\frac{ds}{s}>0 \\
    \implies &G(\alpha_p)>0,
\end{empheq}
but this contradicts $\alpha_p\in(\gamma,\kappa]\implies G(\alpha_p)<0$, hence $\alpha_p\notin N$.

Next, suppose $\alpha_p\notin P$, then $u(\alpha_p,r)>0$ and $u'(\alpha_p,r)<0$ for $r>0$. That implies $u(\alpha_p,r)\downarrow l\geq0$ as $r\uparrow\infty$ and by \ref{llemma} $l=0$. Observe \eqref{ivpint} for $r$ tending to infinity, 
\begin{empheq}{align*}
	\underset{r\to\infty}{\lim}\big[&G(\alpha_p)=G(u(\alpha_p,r))+\frac{1}{2}\big[u'(\alpha_p,r)\big]^2+(N-1)\int_0^{r}\big[u'(\alpha_p,s)\big]^2\frac{ds}{s}\big] \\
    &G(\alpha_p)=G(l)+\underset{r\to\infty}{\lim}\frac{1}{2}\big[u'(\alpha_p,r)\big]^2+(N-1)\int_0^{\infty}\big[u'(\alpha_p,s)\big]^2\frac{ds}{s}\big] \\
    &\text{noting that }G(l)=G(0)=0,~\underset{r\to\infty}{\lim}[u'(\alpha_p,r)]^2=0\text{ (see proof of \ref{llemma})} \\
    &G(\alpha_p)=(N-1)\int_0^{\infty}\big[u'(\alpha_p,s)\big]^2\frac{ds}{s}\big] \\
    \implies &G(\alpha_p)>0,
\end{empheq}and again, since $\alpha_p\in(\gamma,\kappa]\implies G(\alpha_p)<0$, a contradiction is reached and hence $\alpha_p\in P$. 

Conclusion: $(\gamma,\kappa]\subset P$ and $P$ is non-empty.

\subsection*{$P$ is open} To prove that $P$ is open, note that for $\alpha\in P$, $$r_0=\inf\{r>0,~u'(\alpha,r)=0,~u(\alpha,r)>0\}>0$$ and\begin{empheq}[left = \empheqlbrace]{align*}
	&u(\alpha,r)>0\quad\text{for all }r\in[0,r_0) \\
    &u'(\alpha,r)<0\quad\text{for all }r\in(0,r_0).
\end{empheq}
From the \eqref{ivp} follows $u''(\alpha,r_0)=-g(u(\alpha,r_0))$ and considering $u''(\alpha,r_0)=0$, since $0<u(\alpha,r_0),\alpha$: $u(\alpha,r_0)=\gamma,~u'(\alpha,r_0)=0$ and by [[ uniqueness argument ]] we conclude $u(\alpha,r)\equiv\gamma$, an impossible solution [[because]]. Now suppose $u''(\alpha,r_0)\neq0$ and because $\alpha\in P$, $u''(\alpha,r_0)>0$. This implies there exists a $r_1>r_0$ such that $u(\alpha,r)>u(\alpha,r_0)$ for all $r\in(r_0,r_1]$ and [[because ...]] for $\alpha^*$ near $\alpha$ we have for all $r\in(0,r_1]$\begin{empheq}[left=\empheqlbrace]{align*}
	&u(\alpha^*,r_1)>u(\alpha^*,r_0) \\
    &\alpha^*>u(\alpha^*,r)>0
\end{empheq} which implies $\alpha^*\in P$ and hence $P$ is open. Similarly, }
